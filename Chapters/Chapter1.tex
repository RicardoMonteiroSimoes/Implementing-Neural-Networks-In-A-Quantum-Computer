% Chapter 1

\chapter{Quantum Embedding}
\label{chapter:quantum_embedding} % Main chapter title

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 

%comment these back in when you remove Chapter0 from the document

%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Quantum Data Encoding}\label{section:quantum_data_encoding}
Quantum data encoding or quantum data embedding\footnote{The terms \textit{encoding} and \textit{embedding} can be used interchangeably in this context.} describes the process of loading classical data in a quantum circuit by encoding it into the state of the qubits. In fact the classical data is encoded in a Hilbert space using a quantum feature map. 

There are multiple ways of encoding classical data onto quantum states (see list \ref{list:encoding_patterns}) using a quantum feature map which directly affects the computational power of the quantum circuit, emphasizing that the encoding is a crucial part in designing quantum algorithms.\cite{Quantum_machine_learning_in_feature_Hilbert_spaces_2019,Supervised_learning_with_quantum-enhanced_feature_spaces_2019,Quantum_embeddings_for_machine_learning_2020,PennyLane_QuantumEmbedding,PennyLane_QuantumFeatureMap,schuld2021supervised,leymann2019pattern}\par

\noindent An incomplete list of encoding patterns for quantum algorithms\cite{schuld2021supervised,Weigold2021_ExpandingDataEncodingPatterns,leymann2019pattern}: \label{list:encoding_patterns}
\begin{itemize}
    \item Basis Encoding (See section \ref{section:basis_embedding})
    \item Angle Encoding or Tensor Product Encoding (See section \ref{section:angle_embedding}) \cite{leymannBitterTruthGatebased2020}
    \item Amplitude Encoding \& Repeated Amplitude Encoding
    \item Quantum Associative Memory (QUAM) Encoding
    \item Quantum Random Access Memory (QRAM) Encoding \\\textit{(No hardware implementation of QRAM exists until today \cite{Weigold2021_ExpandingDataEncodingPatterns})}
    \item Coherent State Encoding
    \item General Near-term Encoding
    \item Divide‑and‑conquer Encoding \cite{araujoDivideandconquerAlgorithmQuantum2021}
\end{itemize}

\subsection{State Preparation (Initialization)}\label{subsection:state_preparation}

The section in a quantum circuit where the classical data encoding is initialized is referred to as \textit{state preparation}\cite{leymann2019pattern,Weigold2021_ExpandingDataEncodingPatterns} (see figure \ref{fig:circuit_state_preparation}) and can consist of multiple different gates depending on the requirements of the chosen encoding and the quantum algorithm. 

\begin{figure}[!h]
    \centering
    \scalebox{1.0}{
        \Qcircuit @C=1em @R=.7em {
            \nghost{ {q}_{0} :  } & \lstick{ {q}_{0} :  } & \multigate{2}{state\break{}preparation} & \rstick{\cdots} \qw \\
            \nghost{ {q}_{1} :  } & \lstick{ {q}_{1} :  } & \ghost{state\break{}preparation} & \rstick{\cdots} \qw \\
            \nghost{ {q}_{2} :  } & \lstick{ {q}_{2} :  } & \ghost{state\break{}preparation} & \rstick{\cdots} \qw
        }
    }
    \caption{Abstract example quantum circuit with 3 qubits which encodes classical data and starts with a \textit{state preparation} routine}
    \label{fig:circuit_state_preparation}
\end{figure}

There is a trade-off between the following three major criteria\cite{Weigold2021_ExpandingDataEncodingPatterns}:
\begin{itemize}
    \item \textit{The amount of qubits needed for the encoding should be minimal}, because current devices are of intermediate size and thus only contain a limited amount of qubits
    \item \textit{The number of parallel operations needed to realize the encoding should be minimal to minimize the width of the quantum circuit} - ideally, the loading routine is of constant or logarithmic complexity
    \item \textit{The data must be represented in a suitable manner} for further calculations, e.g., arithmetic operations.
\end{itemize}

\section{Basis Embedding}\label{section:basis_embedding}
\todo{add basis embedding (binary)}


\section{Angle Embedding}\label{section:angle_embedding}

Whilst angle embedding is not optimal as it requires $n$ qubits to represent $n$-dimensional data, it is efficient in terms of operations and directly useful for processing data in quantum neural networks\cite{Weigold2021_ExpandingDataEncodingPatterns,leymannBitterTruthGatebased2020}. Weigold et al.  state that only single-qubit rotations are needed for the state preparation routine which is highly efficient and can be done in parallel for each qubit. \break{}
The experiments are limited to angle encoding in the quantum circuits where the value is directly encoded into the rotation angle of the qubit state. Parameterizable gates\cite{qiskit_rygate_nodate} are used for the encoding. A detailed explanation of the used $\mathrm{RY}(\theta)$ gate is available in chapter \ref{chapter:rotation} \break{}
 
Consider the example in figure \ref{fig:example_encoding_circuit_ry} where the features $x, y$ are angle encoded onto the qubits $q_0, q_1$ using the $\mathrm{RY}\theta$ rotation gate, where $\theta$ is replaced with the corresponding feature. 

\begin{figure}[!h]
    \centering
    \scalebox{1.0}{
        \Qcircuit @C=1.0em @R=1.0em @!R { 
            \nghost{ {q}_{0} :  } & \lstick{ {q}_{0} :  } & \gate{\mathrm{R_Y}\,(1.25)} & \qw & \qw\\ 
            \nghost{ {q}_{1} :  } & \lstick{ {q}_{1} :  } & \gate{\mathrm{R_Y}\,(2.3)} & \qw & \qw  \gategroup{1}{3}{2}{3}{.7em}{--}\\ 
        }
    }
    \caption{Circuit with grouping around the \textit{state preparation}}
    \label{fig:example_encoding_circuit_ry}
\end{figure}

The corresponding equation \ref{equation:angle_embedding_two_hadamard_example}, as shown by Weigold et al.\cite{Weigold2021_ExpandingDataEncodingPatterns}:

\begin{equation}
    \centering
    \begin{split}
        \ket{\psi} &=\ \begin{pmatrix}\cos{\frac{1.25}{2}} \\ \sin{\frac{1.25}{2}}\end{pmatrix} \otimes \begin{pmatrix}\cos{\frac{2.3}{2}} \\ \sin{\frac{2.3}{2}}\end{pmatrix} = \begin{pmatrix}
            \cos{\frac{1.25}{2}}\cos{\frac{2.3}{2}}\\
            \cos{\frac{1.25}{2}}\sin{\frac{2.3}{2}}\\
            \sin{\frac{1.25}{2}}\cos{\frac{2.3}{2}}\\
            \sin{\frac{1.25}{2}}\sin{\frac{2.3}{2}}
        \end{pmatrix}
    \end{split}
    \label{equation:angle_embedding_two_hadamard_example}
\end{equation}

\newpage
This example can be written in Python with the \href{https://www.pennylane.ai}{Pennylane.ai} library:

\begin{minted}{python}
# pennylane.ai python library angle embedding example
import pennylane as qml
from pennylane import numpy as np

# features
x = 1.25
y = 2.3
data = np.array([[x, y]])

# quantum device (simulator) and circuit
dev = qml.device('default.qubit', wires=2)

@qml.qnode(dev)
def circuit(data, probs=False):
    for i in range(len(data)):
        qml.RY(data[i][0], wires=0) # input feature x
        qml.RY(data[i][1], wires=1) # input feature y
    if probs:
      return  qml.probs(wires=range(2))
    return  qml.state()

# print the probabilities
print("State vector:")
print(circuit(data))
print("Probabilities:")
print(circuit(data, True))
\end{minted}

\noindent The code then returns the probability vectors:
\begin{minted}{text}
State vector:
[0.33126825+0.j 0.74021789+0.j 0.23900489+0.j 0.53405569+0.j]
Probabilities:
[0.10973865 0.54792253 0.05712334 0.28521548]
\end{minted}

\newpage
The same example written in Python with the \href{https://qiskit.org/documentation/}{qiskit.org} library:

\begin{minted}{python}
# qiskit.org python library angle embedding example
from qiskit import QuantumCircuit
from qiskit.quantum_info import Statevector
import numpy as np

# features
x = 1.25
y = 2.3
data = np.array([[x, y]])

# create circuit
circuit = QuantumCircuit(2)
for i in range(len(data)):
  circuit.ry(data[i][0],0) # input feature x
  circuit.ry(data[i][1],1) # input feature y

# get the probabilities
state = Statevector.from_instruction(circuit.reverse_bits())
probs = state.probabilities()

# print the probabilities
print(state)
print("Probabilities:")
print(probs)
\end{minted}

\noindent The code then returns the probability vectors:
\begin{minted}{text}
Statevector([0.33126825+0.j, 0.74021789+0.j, 0.23900489+0.j,
             0.53405569+0.j],
            dims=(2, 2))
Probabilities:
[0.10973865 0.54792253 0.05712334 0.28521548]
\end{minted}

\section{Data Preprocessing}
\todo{explain the problems first, then the solution and why}
As in classical machine learning, creating a usable classifiers requires the preprocessing of the avaliable data. This can be achieved in a plethora of different ways, for example, mean reduction, feature scaling, normalization or padding. Depending on the input data and the chosen quantum data encoding, preprocessing is a crucial or even mandatory step\cite{PoincarDataPreprocessinForQuantumMachineLearning_2021,VariationalClassifierPennyLane,SHRIVASTAVA20201849}. 

The data used in our experiments is scaled to different ranges using \code{sklearn} \code{MinMaxScaler}\cite{scikit_sklearnpreprocessingminmaxscaler_nodate} and \code{StandardScaler}\cite{scikit_sklearnpreprocessingstandardscaler_nodate}. The \code{StandardScaler} centers and scales the data to unit variance and the \code{MinMaxScaler} is used to additionally scale the data between a given range $[x, y]$, where $x < y$, for the angle embedding. The rotation gates $\mathrm{RY}$, $\mathrm{RX}$ and $\mathrm{RZ}$ have a maximal rotation angle of $\pi$ before a turn around starts.
\todo{Add more explanation}
\todo{Add bloch spheres to make the point with turn around and measuring Z resulting in the same probability}

